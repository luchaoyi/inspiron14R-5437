<CS299>:
GLM:
    ASSUME
    1.假设y|x;@满足某种指数分布族EF(n); 
    2.我们估计目标为期望E[T(y)|x]=h(x);
    3.n=@^T*x
    训练:
    4.maxlnL(@)，最大对数似然性估计-->训练方法.
    
    -->logstic回归：假设服从伯努利分布
        1.y|x ~ B(o) --> o=sigmod(n);
        2.E[y|x]=p(y=1|x)=o=h(x)
        3.n=@^T*x --> h(x)=o=sigmod(n)=sigmod(@^T*x)
    -->线性回归:假设服从高斯分布
        1.y|x ~ N(u,o^2) -->u=n
        2.E[y|x]=u=h(x)=n
        3.n=@^T*x --> h(x)=@^T*x

生成学习算法:
    针对不同类数据分别建模，比较哪个匹配度更高
    多种不同的x|y分布假设都可以得到后验分布p(y=1|x) is logstic,所以logstic建模鲁棒性更强.
    生成学习算法，做了更强的假设.需要数据更少.
    
	朴素贝叶斯
		概率轮链式法则 p(x1,x2,...xn)=p(x1)*p(x2|x1)*p(x3|x2,x1)*...p(xn|x1,x2,...xn-1)
		独立性假设 p(xn|x1,x2,...xn-1)=p(xn) -> p(x1,x2,...xn)=p(x1)*p(x2)*...p(xn)
	
学习理论与VC维:
    H是假设空间|H|=k,f是理想函数，机器学习是从有限的样本S中得到g，来逼近f,目标是使
    1.Err_train -> Err_dream 
    2.Err_train - >0

    Erm是最小化Err_train,模型越复杂，拟合度越高可以更精确拟合样本使Err_train->0，随着模型复制度增大，Err_train与Err_dream距离增大，泛化能力降低。所以模型复制度不足会欠拟合,不能精确学习样本，过大会过拟合。

    对于|H|=INF,VC(H)是对H(复杂度)拟合能力的度量.VC(H)一般情况等于H中自由参量个数.
    误差界:固定大小样本,模型误差与模型复杂度关系.
    样本界:固定误差，模型复杂度，所需要的样本数量下界.
    理论上m=10000*VC(H),实际经验m=10*VC(H),因为VC bound 是粗略的上界.

    正则化：加入了模型复杂度约束SRM，降低了VC(H),避免了过拟合.


EM算法:
	含有隐变量的参数最大似然估计
	E-step:
		l(@)>=J(Q,@),此时取隐变量Q使l(@)==J(Q,@),此时得到的J是l的最紧下界.
		这一步也相当于固定@下使J最大化的Q.
	M-step:
		此时是在Q固定下使下界J最大化的@,使下界最大化
	
因子分析:
	假设现有X背后有一组隐变量Z控制生成X.
	1.假设X=u+lambda*Z+e ，Z~N(0,I),e~N(0,&)
	2.==>X~N(u,lambda*lambda.T+&)
	3.l(u,lambda,&)最大似然估计不能解出u,lambda,&。因此EM算法估计参数
	4.EM==>u,lambda,&


PCA	
	样本去中心化
	计算XX.T
	求XX.T的特征值和特征向量
	
	去中心化是必须的，由协方差定义得到，去中心化后XX.T才是协方差矩阵
	去中心化后，在标准化得到的XX.T是相关矩阵
	当样本不同维度的量纲差异较大时需要去中心化
	
	主成分的特征向量有两个约束条件：（1）特征向量的模为1；（2）特征向量两两正交。在这两个条件的制约下，一个特征值对应两个方向相反的特征向量a和-a。
	因此需要再设定一个约束条件，取值最大的样本的主成分的得分必须大于取值最小的样本的主成分的得分，满足这个条件的特征向量就只有一个了，主成分得分是主成分特征向量和原始特征向量的相关性。
		
	
蒙特卡洛方法
	当所要求解的问题是某种事件出现的概率，或者是某个随机变量的期望值时，它们可以通过某种“试验”的方法，得到这种事件出现的频率，或者这个随机变数的平均值，并用它们作为问题的解，这就是蒙特卡罗方法的基本思想。
	
	
svm:
	通过间隔解决了样本复杂度问题，通过核方法解决计算复杂度问题.
	
强化学习
		M0:基本MDP
			{S,A,Psa,R,Gamma},给定了状态集,动作集，状态动作转移概率，每个状态的即时回报，贴现因子		
			初始状态s0,给定策略P,解贝尔曼方程组(每一个状态一个方程，状态越多方程越多)
			可以得到策略P下的每一个状态的V,V(s0)为从s0出发采用策略P得到的价值				
			每一个策略P都会得到V(s0),最大的V(s0)的策略是最优策略
			策略迭代
				随机初始化一个策略P,解方程得到所有状态的V
				在解出V的情况下计算每一步策略得到新的策略P',更新P=P'
			
			值迭代
				初始所有V为0,然后在此V下解得到最优策略P
				在最优策略P下计算价值得到V',更新V=V'
			/*解方程组的数值方法就是迭代->收敛*/
		M1:最简单的MDP给定了5元组所有信息.
				if不知道Psa,需要从数据统计得到Psa的估计 
				
		M2:机器人走迷宫是离散状态，车子平衡杆是连续状态MDP
			>连续状态空间可离散化为离散空间，划分粒度决定精度和计算成本
			>大多数问题状态空间远远大于动作空间，即状况多，选择少。状态连续，动作离散直接计算
				V(.)价值函数，每一个S->V(S),代表状态S的价值,离散状态可以直接解方程迭代计算
				平衡车连续状态，使用线性回归表示V(S)=theta.T*S，拟合值迭代算法：
					随机采样一些状态S0,S1,...;初始化theta为0，则V(S)为0
					在all V(S)=0下计算策略更新V(S),更新V(S)，得到{s,V(s)}
					{s,V(s)}执行线性回归得到theta
	
		M3:前面模型R是状态即时回报，是S->R(S),更改R为(S,A)->R(S,A),即R为状态,动作的函数
		M4:有限时间步MDP
		M5:
			状态转移过程 S(t+1)=AS(t)+Ba(t)+w(t)
			回报函数 R(st,at)=-(st Ut st+ at Vt at)
	
							
#------------------------------------------------------------------------#	
#<机器学习基础教程>:
1.假设数据由y=f(x;w)+e模型生成，则f(x;w)是决定性的确定部分，有时候代表一种趋势，e称为噪声，代表了随机部分。e~N(0,&^2),y~(f(x,w),&^2),f(x,w)不是随机变量，不会改变数据的分布.
2.核方法:x->@(x),x被映射到高维空间。k(xi,xj)=<@(xi),@(xj)>,通常得不到核函数k对应的@，因此无法得到@(x),。因此应用核方法步骤:
	1>将原始问题展开为为<xi,xj>內积形式
	2>使用k(xi,xj)替换<xi,xj>,直接计算变换空间內积
3.k均值使用点，和距离定义了一个类结构，（圆结构）统计混合，将每个类表示为一个概率密度,概率分布可以以各种形状来建模类，表达更丰富.
4.
最大似然估计，将待估计的参数w视为一个未知数，在当前样本上，最大化似然性计算w。
贝叶斯方法，将待估计参数w视为一个随机变量，从样本学习关于参数w的分布。将参数w视为随机变量，有助于度量不确定性。
Bayes方法计算参数的后验分布的过程是引入样本(似然性)修正参数的先验估计的过程，随着样本增加，似然逐渐压倒先验的单个分布，先验信念变得越来越不重要。参数w的后验分布,在引入样本后，不确定性减小(分布方差减小)。后验分布提供了引入数据后，不确定性程度的信息.
5.贝叶斯方法步骤:
	1)选择先验，
	2)选择似然，
	3)计算后验,bayes公式:后验=先验×似然/归一化的常量
	4)使用期望预测(w是一个分布，使用w的期望作为w的估计值).
6.计算后验(分母归一化常量通常难以计算):
	*共轭先验:若后验分布与先验分布具有相同的形式，则似然与先验是共轭的*
	
	若共轭先验，则可以通过计算似然*先验(分子)和后验与先验形式相同，得到后验分布的解析解，不用计算分母.
	非共轭,不能使用解析方法计算后验分布，只能采取近似计算,主流技术有:
	点估计:后验分布正比似然×先验，因此使分子最大化的w，也是使后验最大化的w，因此计算w=argmax log(似然*先验)，MAP估计。得到了一个确定值w*,而不是分布.
	拉普拉斯近似:使用高斯分布近似后验分布,并从近似的高斯分布，采样计算期望值(预测计算期望，高斯分布连续，积分难以计算，因此对近似后验分布采样w).
	抽样:直接从后验密度抽样w，计算期望值。（不是用高斯分布近似后验，从近似的后验中采样，而是直接抽样，如MH方法）

#------------------------------------------------------------------------#
#<视觉机器学习>:
K-means:
	改进:
		自适应k
		kernel方法:
			I 转化为內积表示
			II 替换內积为kernel函数 or kernel矩阵
		谱聚类
		二分k
	应用:
		图像分割
		字典学习:聚类中心作为字典元素.
K-NN:
	改进:
		加权投票
		kernel-KNN
组合方法:
	bagging:
		组合基分类器结合bagging随机子空间理论,集成方法应该提高不同基分类器的差异，增加多样性
	boost:
		只要找到一个比随机猜测略好的弱分类器，就可以提升为强分类器
		boosting:
			投票分类器一般集成奇数个，以便决策,例如3个:
				不放回抽取随机样本n1<n,训练一个分类器h1.
				不放回抽取随机样本n2<n,将n1中错分的合并到n2中，训练h2
				抽取n中，h1,h2分类不一致的样本训练h3.
				组合h1,h2,h3.
		adaboost:
			给训练样本初始一致的权值（不能加权的样本，重采样）,
			训练h1,h1分错的样本给予一个更大的权值，训练h2,...
			until精度满足停止生成新的分类器
流形学习:
	是寻找一组高维空间在低维流形空间中表示的方法.
稀疏表示:
	对于向量x，只有少量xi!=0，则x是稀疏的。通过选取字典D-(d1,d2,...dp),将信号表示为此这组基上的稀疏向量，即信号的稀疏表示
字典学习:
	稀疏表示构造需要字典，可以人工构造字典,字典学习，从数据中自适应学习字典。
	不稀疏的数据可能在某个变换域中稀疏,采用p个基本波形来表示当前数据,将数据变换到变换域中
	min{D,A} ||X-DA||+||A||,字典空间表示A,DA为X线性组合。目标是DA可以最优拟合X,并使A稀疏。联合优化非凸，因此采用交替更新D,A的方法优化.
深度学习：
	繁杂的海量数据，难以人工设计出合适的特征和选择合适的浅层模型取分析数据，深度模型可以自动的从数据中学习特征，层层抽象(简单粗暴).
	深度学习模型：
		概率性深度模型:
			试图在观测数据基础上恢复模型中的隐变量的概率分布，训练方法采用最大似然估计.
		确定性深度模型:
			试图最小化特定形式的损失函数.		
#------------------------------------------------------------------------#	
<台大|林轩田>
学习方式
	batch
	online
	active 学习算法主动有技巧的问问题,询问样本x是什么label?如困惑时，难以分类x时
		
学习问题
	1.是否能保证Ein接近Eout
	2.Ein足够小, Ein -> 0	

M=|H|,潜在假设函数的数量
P[Ein(g)-Eout(g)>e]<=2*M*exp(-2*e^2*N)

if M small
	1.
		P[BAD]=2*M*exp(...),BAD代表Ein不接近Eout
		因此M小则Ein不接近Eout的概率很小
	2.
		M很小，潜在选择太少，不一定能找到函数h使Ein->0
		
else
	和small相反

正则化方法是在大的M下，又施加约束使P[BAD]降低.
坏事情重叠使union bound过大,将H={h0,h1,...}重叠的归类	
	从对样本的划分来对线归类，线种类的上界是2^N，有效线的种类<=2^N。
	effective(N)<<2^N,with N->无穷.
		P[Ein(g)-Eout(g)>e]<=2*effective(N)*exp(-2*e^2*N)
	effective(N)依赖于样本(x1,x2,...xN),移除依赖，使用增长函数mH
	mH上界也是2^N
	effective(N)<=mH(N)<=2^N
	when N large,mH(N)<<2^N
	if mH(N)=2^N,存在直线每一种样本分布的情况都可以划分,则说这N个点shattered by H
	mH(k)<2^k,最小k是break point。break point与成长速度mH有关,mH(N)=O(N^k-1)
	if N>2,dvc>2,mH(N)<=N^dvc,dvc是VC维.dvc=k-1
	finite dvc 保证,Eout(g)接近Ein(g)
	dvc和模型参数数量有关，表征了模型复杂度(复杂度越高能力越强)		
	
学习原则
	倾向使用简单模型
	数据采样偏差，影响预测
	谨慎对待偷看数据,难以避免,应该正视它的影响,多做交叉检验不要想当然
		用眼睛看数据，用脑子得到一个归纳,决策受到了影响
		数据缩放，将测试数据和训练数据放在一起做测试数据的缩放，相当于将某些测试数据的信息泄漏到了训练阶段
		看别人论文，受到别人的经验影响
------------------------
/x
注意在支持向量机中用到的推导技巧，将约束优化转化成无约束优化，然后无约束优化在导数=0处最优，因此利用导数=0，产生的式子代入无约束优化来化简无约束优化，导数=0可能会产生一些约束式子，因此又转换成了有约束优化，但转换的过程将以前复杂难以求解的式子变成了简单容易求解的式子
x/
SVM
	通过最大化间隔->最小化||W||->降低复杂度->Ein->Eout,泛化能力
	通过特征变换(核方法)Ein->0,经验误差
	若样本线性可分，根据感知机理论一定会找到一条线，线不唯一，SVM是选择最大化间隔的那条线
	不一定线性可分的SVM,放松约束允许一些错误，并根据错误程度惩罚，尽量得到一个误差小，间隔大(模型复杂度小)的模型.
	

logstic回归
	p(y=1|x;theta)=h(theta.T*x) 
	theta.T*x = 0 p(y=1)=p(y=0)=0.5,最不确定。
	theta.T*x>>0 or theta.T*x<<0,则y=1 or y=0的概率越大。因此若theta.T*x线远离两类样本，则此线的质量更高，作出的判断概率支持度越高.
	
		
SVM+logstic
	将SVM的w,b当作logstic的起始点(可以看作迁移学习的思想)
	/x
		一个模型的解是另一个模型的起始是一种迁移学习
		一个优化算法的解也可以是另一个优化算法的起始，如:遗传+GD
	x/	
	另一种融合方法:概率SVM
		g(x)=h(A*(w_svm.T*&(x)+b_svm)+B),两层学习将SVM当作logstic的隐藏层
		my idea->x->SVM->logstic，进一步，可以将两层学习转换为端到端学习->->若使用高斯核+端到端优化(抛弃SVM的优化过程)则网络变为rbf网络
/×
总结模型融合的方法
	1.迁移学习，将一个模型的经验如权值当作另一个模型的优化的起点
	2.集成学习，多个模型集成
	3.层叠，一个模型是一个层，将前一个模型的输出作为下一个模型的特征多个模型层层叠加形成深度学习模型
×/


SVM回归
	tude 回归,在tube内不惩罚

		
核的三个角度
	高维空间的內积运算
	相似性的度量，越相似，K(x,y)越大
	任何作用于应用的先验信息可以通过核提供给学习算法
多核学习
	*,+,c*等运算可以组合简单核构造新核
	可以对数据不同子集使用不同的核
	可以同时使用多个核，取加权平均
--------
集成学习
	/*
	集成学习有正则化效果;
	集成学习,特征变换，去噪，降维，正则化，核方法，最大化间隔等都是异曲同工的，本质上就是基于现有资料学习，并最大化泛化能力
	*/ 
		不同分类器gt,分类问题投票,回归问题平均.每个模型gt(不同的模型，不同的数据，不同的...	)的差异性很重要，否则融合没有意义.
		多个分类器加权混合时，可以使用训练的方法(优化算法)调整加权的参数（简单的方法是使用错误率），若使用训练样本调整加权参数则是best select best,容易overfit,建议使用测试集调整加权参数.基于训练误差训练单个分类器，基于测试误差优化集成加权参数,训练的方法调整参数，相当于是将gt当作了隐藏层，最后使用了一个线性模型进行决策.
		
	/x	
	一份数据如何构造多份不同的数据
		使用bootstrap构造不同的数据集(有放回抽样),e.g. bagging
		使用KFold构造不同数据集(无放回抽样),e.g. stacking
		boosting方法给样本赋权值,e.g. adaboost
	x/
	
	blending
		多个分类器将原始特征输入，每一个分类器有一个输出，可视为是一种特征转换
					 分类器1,分类器2,...
				样本0 *       *	
				样本1 *       *
		一个普遍的思想 使用分类器提特征
		正确率0.5的分类器是乱猜，没卵用.若正确率p<0.5,将结果反过来则正确率为1-p>0.5
		
	stacking
		训练:
			每一个模型训练数据划分k份以交叉方式检验方式训练每个模型(确切说每种模型训练K次得到了K个模型，训练阶段每种模型训练了K个模型，P种模型，因此相当于P*K个模型),每一份数据数据被没有参加训练的数据预测，得到训练数据的预测结果M*1(假设预测label为1维)
			每种模型K个，每个预测M/k个样本，最终组成M*1的预测,即一种模型通过交叉训练提一行特征，P个模型题P个特征->M*P
			重复上述步骤P次训练P个模型(不同模型差异性大),得到M*P的矩阵,此时相当于将原数据利用模型从M*N转换为M*P
			M*P矩阵作为下一层预测模型的输入训练预测模型
		预测		
			对于预测样本每种模型的K个模型都对样本预测,预测后取平均作为此种模型对样本的输出即一种模型产生一个输出(M_t*K的矩阵平均后变为M_t*1)
			P种模型P种输出，产生M_t*P矩阵,相当于预测样本被变换为P个维度，此时将预测样本输出到下一层预测模型输出预测结果			
			
	bagging
		横向抽样构成有差异的数据集.
		纵向随机抽样特征(无放回抽样d<N),随机子空间.
		
	Random Forest
		基本RF=bagging+C&RT
		OPT0RF=横向bagging+纵向随机子空间+C&RT
			bagging 随机抽取资料
			纵向随机子空间,从特征维度抽样,一次抽取d个维度做一个DT，或每次分支时抽取不同的维度做,随机性越大，多样性越丰富.
		OP1RF=横向bagging+纵向随机投影子空间+C&RT
			随机抽样得到子空间->随机投影得到子空间，将原始空间多个特征随机投影(combination)得到一个子空间.
			
	OOB
		out of bag of gt:没有被gt选到的资料是gt的OOB
		bagging方法可以使用OOB自交叉检验,不需要切两部分交叉检验,用E_OOB作为误差指标，来检验模型.
		
	
	Random Forest特征选择
		特征是否重要，比较特征在伪造的垃圾数据和收集的有用数据的错误率对比得到此数据重要性。即对此特征进行干扰是否会影响分类准确率。
		permutation test
			数据干扰，对第i个维度的数据进行混洗,打乱顺序，张冠李带。
			干扰数据和原数据训练两个分类器，用验证数据集验证比较。
			另一种方法使用正常数据训练一个分类器，干扰验证数据，比较在验证数据上的效果。不用重复训练
			
    AdaBoost	
    	/x局部加权线性回归中样本赋予权重的依据在于样本X空间的相似度，而adaboost赋权依据在于上一个分类器的错误率即label Y空间的相似度x/
     	
    	每一个样本有一个权重，权重代表样本的重要性，越重要则误分惩罚越大.adaboost认为错分的样本需要后续重点关注.
    	初始没有任何先验信息时all样本权重一致，注意这个权重的位置可以融合先验信息.

    	(更关注于错误)每个样本权重的和进行过程中应该越来越小,等价于SVM间隔越来越大,adaboost有最大化间隔的效果。	
    		思考函数和向量的联系
    		向量v给一个index，return v[index]
    		函数f给给一个x,return f(x)
    	每一步找一个函数h使adaboost的误差下降,因此adaboost算法每一步找到的gt就是符合要求的h。
    	AdaBoost-DT需要DT接受weight,怎样将权重放进算法，权重使样本被重视,让DT弱一点，可以通过限制树高方法得到弱一点的树，如切一刀，树高为1
    
    Gradient Boosted 
   		AdaBoost的扩展替换误差函数中的exp,使用感兴趣的其它err function.
   		 Gradient Boosted for 回归
   		 	根据推导当err function使用平方误差时，下一步的h(x)拟合的是(xn,yn-sn),拟合的是上一步的误差的余数
   			gbdt使用DT做回归的基本分类器,每一步拟合余数	   		
   	从集成学习角度看NN,隐藏层节点多是降低错误率会过拟合，多个层是特征多次变换，因此NN适合多层少节点.
   	
------------------------------
