<大数据 互联网大规模数据挖掘与分布式处理 >
	大数据存储和计算成本都很高，很多应用不需要完全精确的结果，因此web挖掘有很多近似算法，概率算法
	一些基本思想有：
		数据分块处理
		位图对数据压缩存储
		以某个比例对全集抽样，在样本上处理数据，以抽样比例推断全集，多次实验取平均值是显而易见的想法。
		大数据处理hash很常用，/*如排除数据快速定位目标上,有某种关系的数据hash到一个桶，缩小范围,同样多次hash显而易见*/
		
相似项
	最小hash和局部敏感hash
		基本思想，相似的文档hash值以较大概率相同
		多次hash，在一起的是候选对
		
	相等项
		hash指纹，hash部分文档
		随机选取位置取部分文档，更好因为,一个网站的网页有相同的风格(页眉，页脚，商标...)
	高相似度项>=J
		找明显的特征，排除大量文档.
		长度，位置，前后缀

频繁项
	Apriori
		生成频繁项集
			Fk-1*Fk-1方法生成频繁项，即前k-1相同的k项集生成k+1项集
			k项集不频繁不参与生成k+1,因为一定不频繁
			对于生成的K+1项集合，依然要进行计数，判定是否频繁，因为两个频繁项生成的k+1不一定频繁
		挖掘关联规则
			P->H的置信度  support((P,H)/support(P)
			从频繁项集生成关联规则的方法与生成频繁项集类似，剪枝方法也类似
	FP
		扫描整个数据库，为单个项建立一张item:count的表，根据item的count，过滤掉数据集所有记录中不满足支持度的item，过滤后将记录按出现次数排序
		扫描过滤重排后的数据集建立FP树,此时FP树压缩存储了整个数据集
		从FP树中挖掘频繁项
			从FP数抽取条件模式基，某个元素的条件模式基是和此元素共现的数据集
			如t的条件基中,满足支持度的单个元素x,和t共现
				t的条件基下的x的条件基和t,x共现
				
	PCY是Apriori的改进
		首先将项->编码为小整数,节省内存
			西瓜，牛奶，苏打水->0,1,2
		对C1统计计数，去除不频繁的
		生成一个(i,j),不存储，hash到一个桶，桶计数v增加，最终计数大于阈值S的是频繁桶
		后面判断(i,j)时不扫描数据库，首先i频繁，j频繁(i,j),hash是频繁桶,(i,j)才是有可能频繁的,否则直接排除
		将hash桶压缩为位图,1代表频繁桶,0代表非频繁桶
		进一步改进
			使用多个hash或进一步hash，(i,j)在多次hash均在频繁桶才频繁，减少伪正例	
			
	有限扫描算法SON
		step 1
		数据分块，每个块运行频繁项发现算法阈值S/P,P个块
		若项在数据集中多于S个则，至少有一个块大于S/P阈值的，若每一个块都少于，必然不频繁,因此SON选出的是候选对不存在伪反例(在全集频繁在样本不频繁).
		step 2
		选出的候选对，可能包含伪正例(在某一块集中频繁，整个数据集阈值不足)，对候选对扫描整个数据集去除	
		
	Toivonen算法
		首先抽样一个小样本，在小样本选出频繁对和不频繁对.
		构造反例边界来度量此次抽样的效果，效果不好则放弃此次结果，否则则输出
		
		反例边界由在小样本上不频繁的集合但其子集却是频繁项的项构成,如{A,B}样本上不频繁但{A},{B}样本上频繁.
		扫描整个数据集，计数反例边界中的项数
			若反例边界的项在整个集合仍然不频繁，说明这次抽样，值得相信.
			否则，放弃重来
			
/
高维空间索引结构近似查询算法		
	相似性查询有两种基本的方式：
		一种是范围查询（range searches），另一种是K近邻查询（K-neighbor searches）
			范围查询就是给定查询点和查询距离的阈值，从数据集中找出所有与查询点距离小于阈值的数据；
			K近邻查询是给定查询点及正整数K，从数据集中找到距离查询点最近的K个数据，当K=1时，就是最近邻查询（nearest neighbor searches）
			
	特征匹配算子大致可以分为两类
		第一类是线性扫描法，即将数据集中的点与查询点逐一进行距离比较，也就是穷举，缺点很明显，就是没有利用数据集本身蕴含的任何结构信息，搜索效率较低，
		第二类是建立数据索引，然后再进行快速匹配。因为实际数据一般都会呈现出簇状的聚类形态，通过设计有效的索引结构可以大大加快检索的速度。

	索引树
		基本思想就是对搜索空间进行层次划分。根据划分的空间是否有混叠可以分为Clipping和Overlapping两种。
			k-d树
				划分空间没有重叠
				二叉树
				决策树思想，在n个维度上计算数据集的方差，选择方差最大维度为切分维度，数据方差大表明沿该坐标轴方向上的数据分散得比较开，在这个方向上进行数据分割有较好的分辨率。在选择的切分维度上，对数据进行排序，选择中间点切分数据，到left和right,递归调用直到|数据集|<=设定阈值.选择中值划分，构造的树比较平衡，搜素速度更快(->BST).
			
				->随机k-d树,遵循最优指导到引入随机的思想，不一定选择最大方差，而是从最大k个方差维度随机选择一个
			层级k-means or k-medoids聚类树
				利用聚类划分数据集		
	LSH局部敏感hash
		是能高效处理海量高维数据的最近邻问题,构造一种hash函数使相似项大概率hash值相同
/				
	
		
		
		
	
		
		
		
		
