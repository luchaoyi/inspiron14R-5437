计算机组成与体系结构性能设计|
cpu性能设计
	分支预测
	数据流分析 指令乱序执行
	预取
	流水线
	并行 avx/多核/流水/超标量...
	cache
	协处理器
	
障碍
	功耗
	连接线RC延迟
	存储器落后

Bus
	data/addr
	控制线 在模块间发送命令和时序，控制data/addr的使用

Cache 
	cache m行每行K个字
	存储2^n个地址，M=2^n/K,按照K字划分为M个块，主存的M个块被映射到cache的m个行
	cache行有标记，标识行存储了哪个地址的数据
	映射策略 
	替换算法
	写 
		写直达 同时写cache和mem,其它cpu监视mem,维持自己的cahce一致性
		写回 只更新cache，淘汰时写主存
		
	多核一致性 - mesi协议
		监听协议 写某个cache前首先通知其它监听者此cache对应内容作废
		
Mem*
	WE write enable
	OE out enable
	RAS 行选通
	CAS 列选通
	先激活一行，行数据进入到row buffer,然后在row buffer选择列，切row开销大
	多bank交叉Mem
		每个bank是独立读写，将连续字的地址映射到不同的存储体，K个存储体可同时提供读/写服务
		连续的数据块分布位于不同存储体，被同时读写，如果在同一个bank且数据跨行，则要切多个row
	ddr->ddr2->ddr4	
	存储器fence 
		保证fence指令前后的内存访问指令乱序不越过fence
IO
	编程式IO处理器直接发出指令，控制IO并等待完成
		发出操作
		周期性测试状态
		读/写数据
	中断IO 不检测IO,IO完成后中断cpu
	DMA 接管cpu负责的IO<->Mem的数据传输，窃取cpu总线的使用

cpu
	TLB
		读取一个vaddr的数据，两次IO 
			读取页表,vaddr-raddr转换
			访问数据
		TLB一个cache 存储最近使用的页表,加速地址翻译
	大寄存器组方案
		寄存器窗口
			过程调用和返回是频繁的，每次传送和返回少量局部变量和参数，大多过程调用深度较窄
			将寄存器分划分为重叠的窗口，每个过程指派不同窗口(一组寄存器用于参数和返回值)，避免寄存器与内存的频繁<->
		全局变量指定几个固定寄存器
		#cuda GPU 不同线程使用不同寄存器组
	超标量与超流水
		多个流水线并行
		一个时钟执行多个操作
		受限于相关性
		reg rename 接触一些相关性
	Intel 
		cisc指令被译码为多个risc微指令，微指令以超标量执行
	Arm
		指令译码后依据不同类型在不同流水线执行，不同类型计算和io并行
		io 队列
		alu 普通计算队列
		乘法计算队列
		浮点计算 队列
		浮点乘 队列
		
	微程序
		每个指令周期做的事情被分解为更小的微操作序列，被称为微程序/固件
--------------
计算机组成与设计
计算
	mmx实现	
		运算器进位链分段，64bit运算器可同时计算多个8bit数据
	mul 移位累加构成
	
LRU
	1bit非精确LRU
		一个bit，页使用时置位，os定期将bit清0,淘汰时直接淘汰为0的页面
		
GPU
	高度多线程
	不依赖多级cache隐藏mem访问长延迟，使用大量线程，在io时可以切换执行其它无关io的线程
	编程接口 
		opengl direct3d 图形编程接口
		cuda 通用并行计算接口
	tesla 
		SP
			每个SP(标量处理器核)包含整数和浮点运算单元，有独立的RegFile(1024个通用寄存器)
			硬件多线程，支持高达64个线程
			每个线程处理器执行标量指令，易于编译器优化
		SM
			硬件管理和并发768线程，调度开销为0,每个线程有自己的寄存器组
			一个wrap内线程共享取指发射单元，可以合并访存
			wrap为基本单位，32个线程共享一个pc和stack，执行相同操作
	volta
		int32计算单元，以前int运算使用的是float单元
		每个线程有独立的pc和stack可独立调度,因此可支持syncwarp线程wrap内同步
		tensor core
			混合精度矩阵MAC
			一个时钟周期实现 4x4x4矩阵的 D=A*B+C
			wmma api
				仅提供warp级别api
				以WARP为单元执行，一个WARP中32个线程合作完成一个16×16×16的矩阵mac运算
				// 16*16*16、32*8*16和8*32*16等基本WMMA形状不太匹配
				
	PTX
		伪操作
			版本，target
			指定符号和地址等
			底层性能调整的机制，PTX支持以下指令，这些指令将信息传递给后端优化编译器
		标量指令集
			opcode.type d,a,b,c
			@p | @!p 前缀使用断言寄存器断言是否执行 #条件执行
		支持矩阵乘法和累加（ wmma ）操作，特定shape矩阵mma	
		video指令 scalar and simd指令
		
		SIMT
			独立的线程寻找数据并行的机会
			在wrap内线程具有相同执行路径时，可同时执行它们，也可以在他们出现分支时独立的执行线程
			相比SIMD机器，不用显式表达并行性,且可以编码为边界条件显式编码(remain seg)		
			/*
				首先，每个线程是标量的，编译器优化和cpu无区别
				其次，对一个wrap的线程分析执行路径，在分离的不同路径串行，合并的路径并行
				 A
				/  \
			   C   D
				\  /
				 E
				 基本块A和E可以合并wrap并行执行
			*/	
		tensorRT
			量化精度校准
			网络层的合并
			模型编译
				训练好的网络(结构和权值) -> 量化精度校准量化/layout等 -> 离线模型
											   层融合
											   其它优化
			部署 离线模型+runtime
