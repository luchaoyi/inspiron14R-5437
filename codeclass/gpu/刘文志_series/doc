并行算法设计与性能优化 algorithm a
1.
并行程序设计方法学
	大型软件项目主要使用面向对象设计方法，but面向对象方法的对象依赖性与并行程序设计要求去除数据和控制依赖向冲突。
	so 面向对象不适用于并行设计，并行设计适合过程化设计和以数据为中心

多机系统适合进程级并行，多核共享内存系统适合线程级并行。混合策略是在节点间使用进程级并行，节点内使用线程级并行.

高层:封装，更多规则，简单，速度慢，易开发，易维护，易移植
底层:细节，灵活，复杂，速度块，难开发，难维护，移植性差

2.
指令级并行
	流水线，需要更好的分支预测，coder需要依据某些原则编写更利于cpu准确预测的代码.
	VLEW并行指令执行调度由编译器确定，硬件不需调度，因此compiler  complexity improve ,hardware complexity decreased
	向量化并行
		SIMD,X86上可以使用汇编语言，内置函数和openmp 4.0 使用SIMD指令
		SIMT

用户线程由线程库管理，内核不知道其存在,开销小，内核级线程由os管理，开销大，由os管理更优化。优势互补，一般将用户线程映射到内核线程

	
预测
	数据预取，利用空间局部特性，对数据预取
	分支预测，预测某个分支可能被执行，加载指令流

时间局部性，访问过的数据随后可能还要访问
空间局部性，当前访问地址附近的地址随后可能被访问

缓存一致性MESI
	M is modified,show data in cache 已经更改,未来某个时刻会写入内存
	E is exclusive,show 缓存数据只被当前核心缓存
	S is shared,show 缓存数据被其它核心也缓存
	I is invaild,show 缓存数据已经失效,即其它核心更改了数据

缓存线cache line ,cache 以cache line为基本读写单位,一次读写>=1个cache line.主流cpu cache line is 64 B,主流GPU cache line is 128B

虚拟存储器
	对内存和IO设备(include硬盘)的抽象.
	
NUMA
	非统一内存访问 ( Non-Unified Memory Access 简称NUMA )，指处理器访问物理内存的时间依赖于该内存所在的物理位置。即在多处理器架构下，CPU访问共享内存的时间要比访问本地内存所需的时间长的多(UMA core 访问存储器速度一致)。NUMA架构在逻辑上遵循对称多处理(SMP)架构.
	利用NUMA优点
		控制流分配内存时分配离自己近的物理内存上
		设置线程亲和性，可以避免控制流在核心间迁移。pthread (pthread_setaffinity_np)和 openmp都提供了设置线程亲和性函数
		
算法and程序性能度量分析
	时间complexity
	空间complexity
	实现复杂度 
		时空复杂度，从宏观上分析时间，空间利用忽略了细节差异。具体实现应考虑指令执行周期，内存访问，cache命中等问题.从硬件细节入手进一步优化代码.

性能度量标准，不同标准适合不同场合，没有银弹
	时间
		time series function return 1970.1.1到现在的秒数
		clock function return 执行程序开始到运行到clock时的cpu计时数目(!=cpu 时钟周期)
	FLOPS,每秒浮点运算数
	CPI
	吞吐量，单位时间内硬件能完成的操作数
	并行度，指没有依赖的指令数量		
	
性能分析工具
	优化以性能分析为前提，对代码进行性能分析找出程序热点，有目标的优化。
	gporf gnu编译器工具包自带
		gcc/g++ -pd/-g选项在编译时插入收集函数运行信息的代码，运行时会将信息写入gmon.out
		使用gprof查看gmon.out
		gprof以函数为单位，统计函数调用次数，执行时间，调用关系
	valgrind 可查找内存泄漏问题
	nvporf nvidia开发，分析CUDA 程序which exec in GPU
	perf linux 内核支持的命令行工具，可以分析整个linux系统
		perf可以获得程序的软硬件计数信息，如指令数，cache命中,分支预测失败等	


串行优化
	系统级别，从软硬件系统分析，cpu,mem，网络，阻塞等情况，判断程序运行情况
	应用级别
		编译器优化
			gcc -O3(-O2) -ffast-math -funroll-all-loops -mavx -mtune=native
			超越函数(Transcendental Functions)指的是变量之间的关系不能用有限次加、减、乘、除、乘方、开方运算表示的函数 
		
		调用高性能库
		去全局变量，全局变量会阻碍compiler优化
		restric 指针,表示指针无别名告诉编译器可放心优化
		条件编译取代分支也可满足可可移植性，且不会生成分支代码
	
	算法级别
		缓存优化
			索引顺序，访问数组时应保证局部性，按存储顺序访问更好
			缓存分块，数据大小太大超出缓存大小容易出现不命中，将数据分块,e.g. 
				分块矩阵乘法
				for i=0;i<N;i+=NB
					for j=0;i<N;j+=NB         #分块 
						for k=0;k<N;k+=NB
							for i0=i;i0<i+NB;i0++
								for j0=j;j0<j+NB;j0++ #块内计算
									for k0=k;k0<k+NB;k0++
										C[i0][j0]=A[i0][j0]*B[k0][j0]

			软件预取，编译器或开发者使用CPU预取指令，将数据预先加载到缓存
			查表法,空间swap时间,将某些值提前计算储存，以后使用时直接查表,表中没有存储的结果在计算.
				e.g. 计算exp(x):可以存储区间某些值的结果，使用时结合线性插值提高计算精度,而插值运算GPU从硬件支持,use GPU 进一步加速
	
	函数级别
		函数优先通过寄存器传参，超量后通过栈传参.
		如果函数参数是struct or class,should 传指针或引用,减少call时复制和return 时销毁的开销
		函数内联
	循环级别
		循环展开
			e.g. 
			for i=0;i<num;i++    
				sum++a[i]
			->
			for i=0;i<num;i+=4
				sum1+=a[i];
				sum2+=a[i+1]
				sum3+=a[i+2]
				sum4+=a[i+3]
			sum+=sum1+sum2+sum3 
			->循环累积，减少寄存器使用
			for i=0;i<num;i+=6
				sum1+=a[i]+a[i+1]
				sum2+=a[i+2]+a[i+3]
				sum+=a[i+4]+a[i+5]
			sum+=sum1+sum2

		循环依赖消除
			重新组织代码顺序
			使用寄存器保存有依赖的存储器，降低依赖对性能的影响.
				e.g.使用临时变量存储数组某些值，数组保存在内存中，临时变量编译为寄存器，因此使用临时变量保存数组某些值可减少访存次数.
			循环拆分去除依赖,利于循环并行化
			

	语句级别，不同语句生成指令数量，类型不同导致性能差异
		分支预测失败会影响性能，优化 
			减少分支
				使用x=(a>0?a:b)语句代替分支
				使用查表法代替分支
			短路运算，if(a&&b),a的运算量小于b,则可以利用此特性
	指令级别
		优化乘除法和mod,这些指令会耗费大量cpu周期
		减少数据依赖，依赖减弱流水线乱序执行能力
		给予编译更多优化信息

	*-*数据依赖相关性会影响cpu指令并行能力,线程级并发能力,编译器优化 
	*-*依赖消除关键使用临时变量，减少访存，try消除依赖.
	*-*cache命中会加速，不命中会影响性能
	*-*给予编译器更多的信息,写出更利于编译器优化的代码，更多的使用编译器优化功能
	*-*更多的了接运行平台软硬件特性，利用特性优化
	*-*无分析，不优化
	*-*数据竞争时，或可使用数据复制去除竞争.
	
	
混合计算:进程中分配线程，线程中使用指令并行.

操作原子性
	为了并行需要硬件会提供一些指令，如锁总线，同步执行等等,os也会提供一些原语，这些原语可能是硬件指令的封装或一些高级算法.	

动态负载均衡
	是在运行时确定负载分配，程序在运行期间依据前一段时间资源使用等情况，对各控制流负载进行平衡，动态分配，消除不平衡.
	集中式负载均衡,以某个控制流为分配中心，其它任务从分配中心获得任务，Master/Slave结构
	分散式负载均衡，控制流无主次，控制流可以从其它控制流获得任务，也可以将任务发送到其它控制流
	
	任务队列->分布式队列+任务偷取	，任务队列可以容易地均衡负载，但集中式任务队列会成为性能瓶颈。因此为每个控制流分配一个私有队列，当自己的队列中没有任务时从其它队列获得任务(任务偷取),减少了锁竞争.
	
并行算法陷阱
	缓存刷新，系统启动，调度，结束process or thread都是耗时的操作，因此不要频繁创建和结束线程，一次创建，多次重复使用(e.g. 线程池技术)
	活锁，两个线程在取得一个锁，尝试另一个锁时，反复释放锁，获取锁，活锁一定会被打破，即不会永远停滞，但会消耗时间
	伪共享，线程访问缓存线上的数据，造成同一缓存线上的其它变量失效,上下文切换也会导致缓存失效.

遗留代码处理
	首先分析热点，然后try对热点并行化
	CPU与GPU之间传输数据代价很高，因此并行化时，应避免在CPU和GPU之间传输数据.
	实现的并行代码如何嵌入原代码
		混合编译,适合同种语言实现的代码，混合编译不同语言时数据类型最可能产生bug
		动态链接库，适合不同语言实现，如python调用c语言OpenMp实现的函数，封装为动态链接库.动态链接库独立于语言，依赖于os的格式规定，linux动态库使用dlopen,dlclose,dlsym。
		

并行算法设计准则
	并行性大概意味者不相关
	串行算法中时间复杂度低的算法可能不易并行
	并行程序的可扩展性指随着核扩展，能进一步提升性能，重复利用硬件资源
	并行算法调试难度大，因此最好一边编码,一边测试
	永远不要假设具体的执行顺序,并行顺序是不定的
	

--------0--------> 坐标轴
<-向下舍入 
->向上舍入
	->向0舍入<- 

正数向0是向下
负数向0是向上

#####################################################
并行编程方法与优化实践 programming b
1.指令级并行
	CPU向量运算指令
		x86 SSE/AVX
			可以直接使用汇编指令调用或使用封装汇编指令的内置函数使用向量指令
		ARM NEON
		
2.程序级并行
	openMP	
	openACC

	cuda&openCL
		cuda扩展了c的语法并提供了API和运行环境
			调用函数可得到错误码，通过它可获取到错误信息
			call API can get or set device
				get count，set当前工作的device是哪个
				特性和配置信息
				驱动版本
				
			数学函数
				max(int,int) 操作int
				fmax(double,double) f操作double 
				fmaxf(float,float) ff操作float

			流
				cuda流类似openCL命令队列,命令队列必须在流中执行.默认为0号流，即默认kernel在0号流执行
				0号流与其它流共存时，会等待其它流执行完成后才执行
				cuda流中命令不能乱序执行
				创建多个流可以并发执行多个kernel
			同步
				cuda提供了3个层次的同步
					__syncthreads() 内核级别，同步一个block的所有线程
					cudaStreamSynchronize,流
					cudaThreadSynchronize、cudaDeviceSynchronize,设备,等待设备启动的任务运行完成后才继续执行

			全局存储器优化
				合并存储访问，不同线程尽量访问相邻的地址空间.
					结构体数组->数组结构体
			纹理存储器
				由硬件支持提供了很多额外的处理功能(边界处理，滤波等).纹理存储器只是利用了纹理缓存,没有具体硬件存储，还是映射到显存.
				
				
			cuda 线程块索引是列优先的，即x维的大小先变化,如索引矩阵,y所有Row,x索引Col
				int Row=blockIdx.y*blockDim.y+threadIdx.y;
				int Col=blockIdx.x+blockDim.x+threadIdx.x;

		openCL
			Host控制device,host是资源的管理者和分配者.
			device包含多个CU(Compute Unit),每个CU包含多个PE(Process Element),PE以SIMD方式执行

			执行模型
				NDRange,work-group,work-item

			openCL命令队列
				主机将命令(动态编译后的核函数)放入队列等待调度，在上下文可以创建多个队列，并发执行.
				同一队列命令可以顺序或乱序执行


			Host与device数据传输
				数据拷贝
				存储器映射

			OpenCL需要将kernel代码读到字符串中然后调用API动态编译返回一个kernel对象然后kernel对象才能添加到命令队列中
			
			
######################################################
科学计算与企业级应用的并行优化 application c
1.
CPU擅长逻辑控制，GPU擅长浮点运算，因此CPU擅长任务并行，GPU适合数据并行
CPU擅长处理分支，GPU应尽量避免分支，以及分支不对齐
现代处理器都加入的SIMD单元，支持向量运算

2.
稀疏矩阵存储格式
	DIA:按对角线方式存，列代表对角线，行代表行.适合存储对角线矩阵.
		(对角矩阵可以用一维向量存储,diag(a00,a11,a22,...,an-1n-1))
	
	COO:
		三个数组存储
		rowIndex
		colIndex 
		value
		(rowIndex[i],colIndex[i]) is value[i]
	ELL:
		一个矩阵存储列索引，一个矩阵存储非零元。行还是行.
		(考虑使用链表存储每个行,行是原来的行,节点是colIndex:value，但矩阵更适合于GPU)
	
	CSR/CSC:
		行优先或列优先压缩存储
		CSR 
			rowOffset
			colIndex
			value

	HYB=ELL+COO
		避免ELL矩阵过胖，即某几行元素比较满，可以设置一个k此行前k个元素以ELL存储，多出的元素存储在COO
		







		
