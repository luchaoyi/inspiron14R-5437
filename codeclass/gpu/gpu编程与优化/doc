<方民权>
SP 也称为core,GPU基本运算单元，早期只能进行单精度浮点运算,后来符合支持双精度.
DP 专门用于双精度浮点运算的单元
SFU	用于计算超越函数的硬件单元，硬件速度更快，使用硬件指令或cuda包装的API可调用它
LT/ST 存取单元

SM/SMX/SMM 由SP,DP,SFU，LT/ST加缓存和线程调度单元等组成

/x
流处理器
	控制流和load/store与计算流分离
	计算单元以阵列组织，使用交叉网络互
向量机
	SIMD
超标量
	一次加载多个指令到指令缓冲区排队，多个指令可按不同功能发射到不同流水线并使用指令调度提供性能
VLEW
	超长指令字，包含多个指令
x/

cuda kernel映射到GPU执行，一个kernel对应一个grid,block映射到SM,thread映射到cuda core,调度的基本单位是wrap,当前包含32线程

	cuda 应用程序
	cuda库
	cuda运行时API,cuda*()
	cuda驱动API,cu*()
		CUdevice 
		CUcontext 基于一个CUdevice创建一个CUcontext,context类似进程，执行资源和操作封装在context内,代码执行首先要初始化context.
		CUmodule  可以加载ptx or cubin到module
		CUfunction 从module可以得到一个kernel function

		CUdeviceptr ->显存
		CUarray             
		CUtexref     纹理
	驱动程序


分支处理
	SIMD/SIMT在同一个wrap中加载同一个指令在一组数据上执行，若不同线程有分枝,如if/else,则cuda执行会退化为串行.
	一个分支执行到分支汇聚点，另一个分支才能执行,wrap是线程调度的基本单元，即同一时刻一定有一组或多组线程以wrap执行.
	

一个循环可以分解到
	多个kernel函数
		在host代码中循环启动多个kernel
	kernel函数中循环
		每个线程代码相同，通过不同的tid等执行不同循环
	分解到线程
		启动线程太多则会有线程切换开销
	上述方法开销依次减小。


GPU存储体系
------------------------------
	寄存器访存延迟最小，位于片上，逻辑上线程私有
	
	共享存储器和L1 cache使用相同硬件资源，共享存储器逻辑上block内共享
	
	常量存储位于显存，但拥有片上常量缓存，可加速访问,平均延迟相当接近全局存储的一半
	纹理存储位位于显存,纹理存储提供了专门的纹理缓存通道，可加速访问,片上提供了高速缓存
	
	局部存储和全局存储都位于显存，延迟相当.局部存储没有专用硬件是从显存虚拟出来的地址空间
	
	主机端有页锁定内存和普通内存
------------------------------
	
	寄存器	
		线程私有，速度最快。线程内声明的普通变量会占用一个寄存器
		
	局部存储 
		线程私有，速度与访问全局存储器相当，非常慢，一般在线程内声明的数组，很大可能映射到局部存储(有可能数组较小，计算简单,映射为寄存器访问)，尽可能少使用局部存储
		
	共享存储
		可实现block内线程通信，使用__syncthreads()同步,共享存储与L1 Cache共用(或单独)一个64KB的存储器.速度非常快.	
		SMX中共享存储器和L1 cache使用同一个物理存储器，共享存储器使用一部分，剩余部分为L1 Cache
		
		静态声明
			__shared__ float array[256];
		动态声明
			extern __shared__ float array[]; //在kernel中size参数指定大小
			
		bank conflict
			 共享存储被交替划分到不同的bank.若以32b(4B)为单位，划分到32个bank,则
				 bank0,...,bank31;
			地址 0-3       28-31  
                 32-35 ... ...
			即地址32与地址0同在bank0中.若不同线程同时(如一个wrap内线程) 0和32，即不同线程访问了同一bank不同地址引发了冲突，冲突导致串行访问，性能损失.
			一般bank数量和wrap内线程数量一致,划分大小则以GPU计算能力为单位(如32bit or 64 bit) 
			应该避免一个wrap内的线程同时访问同一个bank的不同地址,即避免同一个时间下,每间隔32个线程访问同一个bank不同地址.
			不同线程访问同一个bank的相同地址会引发广播操作不同引起冲突.

		volatile 关键字
			将全局或共享存储变量声明为敏感变量，因此每次运算都会读取新值.

		常量存储 
			位于显存 __constant__声明，但同一wrap的线程访问相同常量数据时会启动常量缓存.


		全局存储
			动态分配
				使用cudaMalloc*()分配，使用cudaFree*()释放
			静态声明
				__device__声明

			全局存储在不绑定到纹理时，有两种方法可以利用纹理缓存通道访问全局存储
				使用__constant__ __restrict__  修饰只读的常量全局存储
				使用__lgt()内置函数

		纹理存储
			纹理无法单独存在需要绑定到具体存储单元(全局存储或CUDA数组).
			纹理有1D/2D/3D纹理，1D分层纹理,2D分层纹理
				不同的存储对象，不同的纹理有不同的绑定和访问函数,各种不同的纹理有不同的尺寸限制
				访问纹理的函数需要提供被访问纹理对象和索引，除了全局存储读取函数tex1Dfetch()索引是整数外，其它都是float类型的

			纹理使用步骤:
				定义纹理
				定义存储单元
				绑定
				访问
				解绑定
				释放内存

			纹理访问
				读取模式
					读取指定数据类型
					读取后都转换为float类型

				非/不非归一化坐标
					非归一化，类似常用坐标[0,max)为范围
					归一化,坐标缩放到[0,1]


				滤波模式
					点滤波，直接返回点坐标值
					线性滤波，取坐标两相邻元素线性插值

				寻址模式
					坐标超出寻址范围的处理方式(图像的边界处理,补0,镜像，循环，补边界值等)

		主机端内存
			可分页内存
				use malloc/free 分配/释放，内存页可交换到磁盘,无法使用DMA
			页锁定内存
				cudaHostAlloc和cudaFreeHost分配/释放
				使用cudaHostRegister将可分页内存注册为页锁定,(cudaHostUnRegister),作者测试整体性能比cudaHostAlloc好
				内存一直位于内存空间中不会换出,页锁定内存比可分页内存的传输速率快
			零拷贝内存
				在kernel函数使用API获得执行Host的指针直接访问Host的页锁定内存
				零拷贝访问必须是对齐的，连续的,才能获得性能提升.

				用cudaHostAlloc分配一个声明为cudaHostAllocMapped的页锁定内存
				用cudaHostGetDevicePointer将一个在GPU上的指针指向此内存

		GPU优化的关键在于访存优化，if访存只占计算很小一部分的情况，此时优化可能更多需要针对计算

	
	



