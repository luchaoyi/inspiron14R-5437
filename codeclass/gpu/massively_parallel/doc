大规模并行处理器实战|清华大学出版社

可编程流水线用到顶点处理器和片元处理器
	顶点处理器执行顶点着色阶段设计的程序
	片元处理器执行为像素着色阶段设计的程序

CUDA
	cpu is master host 
	gpu is slave  device 

	执行过程开始于CPU,使用cuda关键字标识的函数在gpu执行，称为kernel函数.
	__host__ 主机函数，在cpu上执行，只能在__host__调用
	__global__ kernel函数在设备(GPU)上执行，只能在__host__函数调用 
	__device__ 在GPU执行，只能在device or __global__调用


	计算过程
		在device cudaMalloc显存,cpu内存数据->设备内存(显存)
		gpu 计算
		计算结果在显存,显存数据->cpu接受到内存,然后cudaFree device 存储空间
		
	cudaMalloc的内存是device内存(显存),host代码不能解引用，否则引起异常
	cuda模型不是共享内存，因为显存和内存不能直接访问，因此需要数据的复制.在device上执行的函数只能使用在device内存的数据


	struct dim3{
	int x;
	int y;
	int z;
	}
	__global__  kernel函数,在cpu调用在gpu执行的函数,kernel函数需要配置<<<dimGrid,dimBlock>>>,一个kernel函数创建一个网格，网格所有线程都执行kernel
	dimBlock和dimGrid都是在主机定义的dim3变量,定义网格是三维的,每个网格中的线程块是三维的,线程块中每一个坐标是一个线程
	
	gridDim预定义变量存储三维网格维度,网格中每一个线程块用blockId标识坐标为(blockIdx.x,blockIdx.y,blockIdx.z)
	blockDim预定义变量存储线程块维度,线程使用threadIdx标识自身坐标(threadIdx.x,threadIdx.y,threadIdx.z)
	一个block中的线程数有最大上限，受限于软硬件平台.因此维度可以变换但不能超过数量
	分层结构
		网格 
			|线程块 
				|线程 

	cuda动态分配的数组缺乏维度信息因此不支持多维度索引,因此需要线性化(一维)存储多维结构并计算索引，可采用行优先或列优先线性化
	三维网格由线程块组成，三维线程块由线程组成

	使用dim3变量定义网格，块维度
	example:

	dim3 dimBlock(128,1,1)
	dim3 dimGrid(32,1,1)
	vecAddKernel<<<dimGrid,dimBlock>>> #一维grid中有32个block,一维block中有128个thread 32*128=4096个线程
	=>
	vecAddKernel<<<32,128>>>,如果都是一维可以直接写数字
	cuda动态分配的多维数组，使用线性一维索引.
	index=Row*colNum+Col , d_in[index] 


	线程同步
		cuda同一个block的线程可以使用__syncthreads()执行Barrier
		cuda不允许不同线程块执行Barrier,不同块不用等待
	
	
	cuda以块为单位分配执行资源，执行资源被组织为SM(多核流处理器,拥有多个SP),几个block会被分配到一个SM上执行
	SM线程数有限，能分配的block有限.因此cuda运行时系统维护一个需要执行的线程块的列表，将分配过的SM执行完毕后，然后分配未执行的
	线程块分配到SM后会划分为wrap,多个连续的线程组织为一个wrap,wrap是SM的线程调度单元,同一个wrap的线程按SIMD模式共同执行.即最小的调度单位不是线程，而是wrap,调度多个wrap避免长延迟等待.
	

	/*
	cpu有操作系统支持进程运行和调度等
	同理=>
	cuda的GPU也有运行时系统支持计算任务资源分配，调度等工作
	*/

	查询device属性
		cuda提供API可查询设备的属性信息
	
CUDA 存储器
	CGMA 某一区域每次访问全局存储器时执行浮点运算的次数比值

	cuda设备存储器类型
		全局存储器/常数存储器
		__device__/__device__ __constant__
			主机代码可读写(发送数据和从它接受数据)
			device可以读写全局存储器,只读常数存储器，host可以将只读的数据传输到常数存储器，供设备只读
			网格所有线程共享,片外存储器速度最慢

		寄存器/局部存储器
			是每个线程私有的
			除数组外的自动变量(没有特别的__device__声明的)是存储在寄存器(速度最快)
			自动数组变量存储在局部存储器

		共享存储器
		__device__  __shared__ 
			是线程块私有的，同一个线程块内共享
			
			静态分配共享存储器
			__shared__ s[64];64固定大小,在编译期可确定大小
			动态分配共享存储器
				<<<grid,block,size>>> 在核函数中指定动态分配的共享存储器大小为size字节，size不是一个固定值，值在运行时确定
				extern __shared__ int s[]; 声明一个block范围内共享的共享存储,执行kernel函数时使用size确定它的大小,size值在运行时,调用kernel前确定

/x
__global__声明的kernel函数由__host__函数调用,kernel<<<gridDim,blockDim,[size],[si]>>>(...),kernel函数被映射到GPU上执行
__device__函数是kernel可调用的普通函数,可视为插入到kernel函数中的代码，即device是kernel的一部分

gridDim网格的三维维度,网格中的每个点是一个block
blockDim,线程块的三维维度,块中的每个点是一个线程
size,可选，需要动态分配block共享存储时使用size指定大小
si,可选，流索引号
x/

	局部性
		算法具有局部性时可以使用小型快速的存储来缓存当前需要大量访问的数据
		为了充分利用有限的缓存，一般将大块数据分块，分阶段加载到小而快的存储中缓存	

	每个SM可容纳线程数和存储资源是有限的，如果每个线程使用过多的存储资源,则可同时执行的线程数就会减少，反而会影响性能.
	

性能优化
	线程块中的线程被划分为wrap,同一个wrap的线程由SIMD硬件执行
	同一个wrap中的线程的控制流能完美对齐时,效率最高。如都执行if分支or都执行else分支
	若一个wrap的线程控制流不能对齐，不同线程执行不同分支，则硬件需要遍历其它路径，确保线程自己做出选择，带来了额外开销.
	if/else与for的不对齐都会引入控制流分支.


	全局存储器带宽受限
		数据分块加载到共享存储器执行
		同一个wrap的线程以SIMD方式同时执行，当wrap内所有线程执行同一条指令访问的是全局存储器中的连续单元时,这些单元的访问会合并为一个访问，访问速度接近全局存储器DRAM峰值。
		将不能合并的访问，加载到共享存储器，共享存储器不需要合并访问优化

	SM资源包含
		寄存器
		共享存储器
		线程块槽
		线程槽
	资源分配相互制约，若某资源不足必然会影响并行性，使性能下降



浮点运算
	浮点数数值计算时会有舍入误差，可以 
		对数值预排序可以避免大数与小数运算时，小数被舍入
		使用数值运算补偿算法对结果修正
	
	数值运算稳定性
		不依赖于计算顺序
		若不同计算顺序产生不同的结果，则数值不稳定
			使用随机化操作可以一定概率避免最坏情况出现


并行编程模式
	卷积
		涉及每个元素上的大量算术运算
		数组操作，输出元素是输入元素的加权和，权值由一个卷积核(一个掩码数组)决定,卷积核中心对应到输出元素位置
		边界处理
		
	scan 
		跳步scan
		归约树跳步scan
		任意长，太长考虑分段并行scan
		
	稀疏矩阵-向量乘
		有很多0的matrix and vector
		CSR
			稀疏行压缩
				matrix =struct {
					//行指针索引元素起始行，两个行指针之间的元素在一行
					//col_index与data数据一一对应存储列索引
					row_ptr=[0,2,2,3]   
					data=[1,2,3,4,5,6];
					col_index[1,2,2,1,3,1]	
				}
				
并行编程和计算思想
	问题分解
	算法选择
	编程实现
	性能调优


Thrust cuda库
	cuda C是比较底层的提供了更多精细的控制,Thrust库更高级更抽象
	BLAS 是数值线性代数库
	Thrust	大多数功能来自4个基本并行算法
		for_each
		reduce
		scan
		sort

OpenCl
	OpenCl的kernel代码是动态编译的，存储在字符串中然后调用API编译得到一个kernel对象
	然后此将此kernel对象添加到cmdQueue中,然后被调度执行.

/************
cuda优化小结
	1.wrap控制流分支
		一个wrap内线程使用SIMD执行,若出现控制流分支如不同线程执行不同的if/else分支，for循环次数不一致,会影响效率.
		因此尽量保证一个wrap线程完美对齐.如数据 长短不一可以填充一些无效元素使其对齐。

	2.存储器优化,主要是减少全局存储器访问
		合并存储器访问，让相邻线程访问相邻内存。
			如
				若矩阵每一个线程访问一行，则以列优先存储矩阵可以使相邻线程访问相邻元素
				结构体数组，转化为数组结构体
					struct f3{                    struct f3_100{
						float x;                 float x[100];
						float y;  =>优化=>       float y[100];
						float z;                 float z[100];
					}
					struct f3[100]               
		利用常数存储器存储不变量，不变量若加载到缓存不用担心一致性问题.
		将全局存储结果部分加载到共享存储器
		利用kernel函数中多使用寄存器存储中间结果
	3.对SM内资源的合理分配

	4.使用cuda硬件数学函数
		cuda提供的硬件数学函数通过特殊硬件SFU执行硬件指令.
		需要注意硬件函数的精度/准确度可能会略低于软件库
************/		
